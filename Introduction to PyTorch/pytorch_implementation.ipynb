{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w98ckV9hSDcO",
        "outputId": "ed0405a9-70a4-47fe-d0cc-8a64bc4ed59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch module\n"
      ],
      "metadata": {
        "id": "hw7Ikv7OViRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P6ORJUHEYa-7",
        "outputId": "b467cb8b-d247-4192-91b2-e5956719b12d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjvC_TbrZwNk",
        "outputId": "c15c1013-d14f-47b3-ff8c-6154cfc61609"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing pytorch sensors"
      ],
      "metadata": {
        "id": "KSZx_-Raadk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "tensor2d = torch.tensor([[1, 2],\n",
        "                         [3, 4]])\n",
        "\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]],\n",
        "                         [[5, 6], [7, 8]]])"
      ],
      "metadata": {
        "id": "CP-gjmiuaglx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor data types"
      ],
      "metadata": {
        "id": "zdNkRBv9axBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "print(tensor1d.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ypmhfQMazho",
        "outputId": "5c008408-cc52-4ad5-9506-615526405db2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch6LOe1Za8ty",
        "outputId": "0fac72af-eb25-4854-a4da-4bb51e7b5cbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "changing tensor type"
      ],
      "metadata": {
        "id": "9MZYLU0gbON5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "floatvec = tensor1d.to(torch.float32)\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9-vVuZCbQqt",
        "outputId": "c951f1c4-4c3c-4555-89b3-864b76a8f689"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "common pytorch tensor operations"
      ],
      "metadata": {
        "id": "JKX5iuS-b3mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = torch.tensor([[1, 2, 3],\n",
        "                         [4, 5, 6]])\n",
        "print(tensor2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-MajjfHb76G",
        "outputId": "304abb03-be68-47be-c115-82cb44fce1cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "size attribute of tensor."
      ],
      "metadata": {
        "id": "8eF-h5-BcHZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Size([2, 3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vef3U9i8cM-f",
        "outputId": "ac34b33b-dc87-4ba2-d145-2745eecfc26d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reshape tensor"
      ],
      "metadata": {
        "id": "IVSiK16qcdDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.reshape(3, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soho1Cllcf1j",
        "outputId": "8bda821a-c9d8-413e-871e-d1ac99d4d2b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.view(3, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qs4-7uQcYP6",
        "outputId": "446698d1-a25f-4f39-8f77-fb6fcf7379bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transpose of tensor: .T function"
      ],
      "metadata": {
        "id": "_PaaSBG7dSxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "difeerence between reshape and view: .view() requires the original data to be contiguous and will fail if it isnâ€™t, whereas .reshape() will work regardless, copying the data if necessary to ensure the desired shape.)"
      ],
      "metadata": {
        "id": "5kB_UcA9c_eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRuod5orbGci",
        "outputId": "9232785f-891b-4cb8-dd4b-f1c2aeafdeee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiply  two matrices in PyTorch using the .matmul method:"
      ],
      "metadata": {
        "id": "VyAibxmqdlsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.matmul(tensor2d.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_NglZ7Sdd6r",
        "outputId": "be753fd7-1936-464d-f09c-43ca98812a54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14, 32],\n",
            "        [32, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiply using  @ operator"
      ],
      "metadata": {
        "id": "6_lzs8hXd3Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d @ tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QyHHZAKdxaa",
        "outputId": "f5001e33-c1d6-4401-c090-1cbc177b99a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14, 32],\n",
            "        [32, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeing models as computation graphs. In the context of deep learning, a computation graph lays out the sequence of calculations needed to compute the output of a neural networkâ€”we will need this to compute the required gradients for backpropagation, the main training algorithm for neural networks."
      ],
      "metadata": {
        "id": "ZbtKd6KFfWUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression forward pass"
      ],
      "metadata": {
        "id": "_2Mdcw8ufnlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2])\n",
        "b = torch.tensor([0.0])\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "loss = F.binary_cross_entropy(a, y)"
      ],
      "metadata": {
        "id": "uL2FRMdgfdEi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing gradients via autograd"
      ],
      "metadata": {
        "id": "gD1_qh0_f9yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)"
      ],
      "metadata": {
        "id": "Ff0wVMrWgELB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grad_L_w1)\n",
        "print(grad_L_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRMwtTx-gV8H",
        "outputId": "44a15ef5-9022-4959-8e77-99df36ba3d55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " PyTorch provides even more high-level tools to automate this process. For instance, we can call .backward on the loss, and PyTorch will compute the gradients of all the leaf nodes in the graph, which will be stored via the tensorsâ€™ .grad attributes"
      ],
      "metadata": {
        "id": "9iKnmaqugqr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfi7M_vgt3W",
        "outputId": "346704a6-bcde-43db-ad90-9675f461f883"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing multilayer neural networks: When implementing a neural network in PyTorch, we can subclass the torch.nn.Module class to define our own custom network architecture. This Module base class provides a lot of functionality, making it easier to build and train models. For instance, it allows us to encapsulate layers and operations and keep track of the modelâ€™s parameters"
      ],
      "metadata": {
        "id": "s0mKIhdsg7at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multilayer perceptron with two hidden layers"
      ],
      "metadata": {
        "id": "OGZMTWlXhZSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "34Dlhy2GhIbe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then instantiate a new neural network object"
      ],
      "metadata": {
        "id": "v2umPMqUhjz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(50, 3)"
      ],
      "metadata": {
        "id": "fHREd0oAhlIO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5VeCbJQht7I",
        "outputId": "ce804e37-6109-420b-915c-473165ce0c61"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKESTJRfh3y4",
        "outputId": "6cc90e22-c213-419c-8c07-8e3bb705ff49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of our neural network model with the preceding two hidden layers, these trainable parameters are contained in the torch.nn.Linear layers. A Linear layer multiplies the inputs with a weight matrix and adds a bias vector. This is sometimes referred to as a feedforward or fully connected layer."
      ],
      "metadata": {
        "id": "NYHpK4dViRS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDiOfGxUiTA_",
        "outputId": "ddde1c09-330b-4043-9c84-4c94ff6e25f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0674, -0.0474,  0.0467,  ...,  0.0790,  0.1056,  0.0750],\n",
            "        [-0.0072,  0.0891, -0.1308,  ..., -0.0801, -0.0441, -0.0744],\n",
            "        [ 0.0250, -0.0301, -0.0515,  ...,  0.0172,  0.0173, -0.0530],\n",
            "        ...,\n",
            "        [ 0.0145,  0.0953, -0.0172,  ..., -0.0507, -0.0989, -0.0439],\n",
            "        [ 0.0057,  0.1315,  0.0733,  ...,  0.1328, -0.0718, -0.0147],\n",
            "        [ 0.0101,  0.0205, -0.0869,  ...,  0.1019,  0.1167,  0.0941]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L_kx4NIigwm",
        "outputId": "e3066202-af53-4ca5-cf8b-71012583075e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KgfQZvViulk",
        "outputId": "92b26693-bfc2-4532-cc5b-28b5c3772b48"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([ 0.0132,  0.0942,  0.0249,  0.0402,  0.1325,  0.0068, -0.0594, -0.0802,\n",
            "         0.0883,  0.1322, -0.0137, -0.0353, -0.1309,  0.0305, -0.1397,  0.0624,\n",
            "         0.0362,  0.0381, -0.1313, -0.0118, -0.0206, -0.0793,  0.0063,  0.1328,\n",
            "        -0.0418,  0.0782, -0.0422, -0.1115,  0.1129, -0.0654],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvYD7rqqi1-c",
        "outputId": "b2f4ee4f-9e88-4996-ab58-44f44c4b223d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using small random numbers as initial values for our layer weights, we can make the random number initialization reproducible by seeding PyTorchâ€™s random number generator via manual_seed"
      ],
      "metadata": {
        "id": "2eem7O8fjXUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnLuQliGjhom",
        "outputId": "35c448a3-0064-4435-ce38-06dd7c283dab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "X = torch.rand((1, 50))\n",
        "out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpqTLHOjtC7",
        "outputId": "08d52480-fe17-4b64-8213-022527dda030"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to use a network without training or backpropagationâ€”for example, if we use it for prediction after trainingâ€”constructing this computational graph for backpropagation can be wasteful as it performs unnecessary computations and consumes additional memory. So, when we use a model for inference (for instance, making predictions) rather than training, the best practice is to use the torch.no_grad() context manager. This tells PyTorch that it doesnâ€™t need to keep track of the gradients, which can result in significant savings in memory and computation"
      ],
      "metadata": {
        "id": "Hu3O3OrUkLbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJfgvV-AkSeZ",
        "outputId": "764b613d-d90c-4fdf-b7dc-44fb1572c985"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, itâ€™s common practice to code models such that they return the outputs of the last layer (logits) without passing them to a nonlinear activation function. Thatâ€™s because PyTorchâ€™s commonly used loss functions combine the softmax (or sigmoid for binary classification) operation with the negative log-likelihood loss in a single class. The reason for this is numerical efficiency and stability. So, if we want to compute class-membership probabilities for our predictions, we have to call the softmax function explicitly"
      ],
      "metadata": {
        "id": "mg989aIukhqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsT5sFWBkiyE",
        "outputId": "eb007790-17e3-40d0-ef40-bcb6a42af1af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating efficient data loaders in PyTorch, which we will iterate over during training"
      ],
      "metadata": {
        "id": "JmPJ4uetks5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creating a small toy dataset"
      ],
      "metadata": {
        "id": "DfiuXYXqlMvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "nStNWSV3k0az"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " create a custom dataset class, ToyDataset, by subclassing from PyTorchâ€™s Dataset parent class"
      ],
      "metadata": {
        "id": "OLHhPz-UlYHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a custom Dataset class"
      ],
      "metadata": {
        "id": "IJbWH-pBldkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "8Vsvx7aPlaAv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this custom ToyDataset class is to instantiate a PyTorch DataLoader. But before we get to this step, letâ€™s briefly go over the general structure of the ToyDataset code.\n",
        "\n",
        "In PyTorch, the three main components of a custom Dataset class are the __init__ constructor, the __getitem__ method, and the __len__ method . In the __init__ method, we set up attributes that we can access later in the __getitem__ and __len__ methods. These could be file paths, file objects, database connectors, and so on. Since we created a tensor dataset that sits in memory, we simply assign X and y to these attributes, which are placeholders for our tensor objects.\n",
        "\n",
        "In the __getitem__ method, we define instructions for returning exactly one item from the dataset via an index. This refers to the features and the class label corresponding to a single training example or test instance. (The data loader will provide this index, which we will cover shortly.)\n",
        "\n",
        "Finally, the __len__ method contains instructions for retrieving the length of the dataset. Here, we use the .shape attribute of a tensor to return the number of rows in the feature array. In the case of the training dataset, we have five rows, which we can double-check"
      ],
      "metadata": {
        "id": "-PNl0ISil-b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuWwv2oLl_TU",
        "outputId": "5891f1ca-7266-4d55-d601-c72ea8d9692c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " weâ€™ve defined a PyTorch Dataset class we can use for our toy dataset, we can use PyTorchâ€™s DataLoader class to sample from it, as shown in the following listing"
      ],
      "metadata": {
        "id": "CqgxKCpSmO1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Instantiating data loaders"
      ],
      "metadata": {
        "id": "UluRqzAumTNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "pxi4i_YNmQBW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qoWQqI5mct9",
        "outputId": "2944e54f-d426-44e0-db05-2535933e45a1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " A training loader that drops the last batch"
      ],
      "metadata": {
        "id": "xD6UDY2Vmwu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "E6X3cEcdm0Zy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izi6t358m4ZS",
        "outputId": "7384d987-5470-4420-d04b-785c56a3cbdf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network training in PyTorch"
      ],
      "metadata": {
        "id": "pITcMRtpnPxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), lr=0.5\n",
        ")\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # Insert optional model evaluation code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeKiPpMpnSmO",
        "outputId": "9bc77e93-9899-4e15-e4d4-b949448d8787"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we have trained the model, we can use it to make predictions"
      ],
      "metadata": {
        "id": "hZC80dmQo4xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdHDJguLpuBv",
        "outputId": "4e987a72-6f8b-44be-df03-6adfe3905973"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goiFhil2pxrQ",
        "outputId": "0253ee41-bfa6-427d-b24a-2201df8ab4a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-hc1hr4p4XL",
        "outputId": "fcfdf65c-4db0-426c-f8bb-701ceb2d8ac7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = torch.argmax(outputs, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eka6tTe_p-uJ",
        "outputId": "86d934a1-de22-4ed2-f798-49f0eda6ecbf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to compute the prediction accuracy"
      ],
      "metadata": {
        "id": "g9ejMKapqOUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()"
      ],
      "metadata": {
        "id": "W3WN7A0VqRU9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_accuracy(model, train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Pt45CYqckz",
        "outputId": "b4f9a811-354f-4521-8310-3e2e5065dbd4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_accuracy(model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdOVRa0tqgg-",
        "outputId": "f2e11d76-6a4f-468c-bb58-cfc6b3d10fe4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Saving and loading models"
      ],
      "metadata": {
        "id": "ZL0pFOONqlOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "Itz_AiDQqn7D"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(2, 2)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyYMhuVTqs9a",
        "outputId": "07bcbab9-633e-48a0-aa56-8d6a8c0fc0d5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-480b0cfeb265>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}